# Generative AI Fundamentals Course

## Course Overview
This repository contains materials and code from a comprehensive Generative AI course, exploring fundamental principles and practical applications.

### Core Topics Covered
- **Generative AI Foundations**
  - Understanding GenAI principles
  - Examples and applications
  - Integration with existing AI technologies

- **Deep Learning & Foundation Models**
  - PyTorch fundamentals
  - Working with transformer architectures
  - Understanding BERT and ChatGPT models

- **Model Fine-tuning**
  - Parameter-efficient fine-tuning (PEFT)
  - Domain adaptation techniques
  - Resource-efficient model training

## Project Implementation
The course culminated in a hands-on project focused on lightweight fine-tuning of foundation models.

### Project Objectives
1. Loading and configuring foundation models
2. Working with Hugging Face datasets
3. Implementing PEFT techniques

### Technical Stack
```python
# Core dependencies
torch==2.5.1
transformers==4.48.0
datasets==3.2.0
huggingface-hub==0.27.1
```

## Skills Acquired
- Understanding and implementing GenAI solutions
- Working with deep learning frameworks
- Foundation model adaptation
- Efficient fine-tuning techniques
- Dataset preparation and handling

## Project Outcomes
- Successfully implemented parameter-efficient fine-tuning
- Worked with Hugging Face's ecosystem
- Applied domain adaptation techniques
- Optimized model performance with minimal computational resources

## Getting Started
1. Clone this repository
2. Install dependencies: `pip install -r requirements.txt`
3. Follow the code examples in sequential order

## License
This project is available under the MIT License.
